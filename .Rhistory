states <- inner_join(states, n)
colnames(states)[3] <- "region"
MainStates <- map_data("state")
MergedStates <- inner_join(MainStates, states, by = "region")
View(MergedStates)
View(n)
state_pop <- read.csv(file="nst-est2019-alldata.csv")
state_pop <- read.csv(file="~/Downloads/nst-est2019-alldata.csv")
state_pop <- select(state_pop, NAME, POPESTIMATE2019)
colnames(state_pop)[1] <- c("states")
state_pop$states <- tolower(as.character(state_pop$states))
n <- left_join(n, state_pop)
View(n)
n$rel_n <- n$n/n$POPESTIMATE2019*1000
View(n)
popular <- dataset %>%
select(username, date, attention, tweet, year, retweets_count)
popular <- popular[popular$year>2018,]
dataset$attention <- dataset$replies_count+
dataset$retweets_count+dataset$likes_count
popular <- dataset %>%
select(username, date, attention, tweet, year, retweets_count)
popular <- popular[popular$year>2018,]
popular <- popular[order(popular$retweets_count, decreasing=TRUE),]
popular <- popular[order(popular$attention, decreasing=TRUE),]
normalize <- function(x)
{
return((x- min(x)) /(max(x)-min(x)))
}
dataset$attention <- normarlize(dataset$replies_count)+
normarlize(dataset$retweets_count)+normarlize(dataset$likes_count)
normalize <- function(x)
{
return((x- min(x)) /(max(x)-min(x)))
}
dataset$attention <- normarlize(dataset$replies_count)+
normarlize(dataset$retweets_count)+normarlize(dataset$likes_count)
dataset$attention <- normalize(dataset$replies_count)+
normalize(dataset$retweets_count)+normalize(dataset$likes_count)
popular <- dataset %>%
select(username, date, attention, tweet, year, retweets_count)
popular <- popular[popular$year>2018,]
popular <- popular[order(popular$attention, decreasing=TRUE),]
View(head(popular, 50))
load("~/Documents/GitHub/OT_analysis/data/dataset_final.RData")
sent <- read.csv(file="~/Documents/GitHub/OT_analysis/results/graph2019_7.csv")
sent <- sent %>%
filter(year==2019)
library(robustHD)
dataset <- dataset %>%
select(id, year, date, time, username, name, tweet, replies_count, retweets_count, likes_count, retweet, retweet_id, reply_to) %>%
filter(year==2019) %>%
group_by(username) %>%
mutate(count=n())
normalize <- function(x)
{
return((x- min(x)) /(max(x)-min(x)))
}
dataset$attention <- normalize(dataset$replies_count)+
normalize(dataset$retweets_count)+normalize(dataset$likes_count)
glimpse(dataset)
users2019 <- dataset %>%
pull(username) %>% unique
summary(dataset)
correlation <- select(dataset, likes_count, replies_count, retweets_count, attention)
correlation$username <- NULL
library(Hmisc)
corr2<-rcorr(as.matrix(correlation))
#install.packages("PerformanceAnalytics")
library("PerformanceAnalytics")
chart.Correlation(correlation, histogram=TRUE, pch=19)
jpeg('~/Documents/GitHub/OT_analysis/results/correlation.jpg', width = 800, height = 800, res=200)
chart.Correlation(correlation, histogram=TRUE, pch=19)
dev.off()
tweets <- dataset[order(dataset$attention, decreasing=TRUE),]
tweets <- select(tweets, tweet, attention) %>%
distinct()
View(head(tweets, 50))
View(tweets[tweets$username=="traveldudes",])
View(tweets[tweets$username=="lumos",])
View(tweets[tweets$username=="katevandoore",])
View(tweets[tweets$username=="bettercarenet",])
View(tweets[tweets$username=="ro_global",])
View(tweets[tweets$username=="childsafe",])
View(tweets[tweets$username=="children_in_fam",])
View(tweets[tweets$username=="epcatuk",])
View(dataset[dataset$username=="epcatuk",])
sentiment
View(sentiment[sentiment$username=="epcatuk",])
View(sentiment[sentiment$username=="epcatuk",])
View(tweets[tweets$username=="ecpatuk",])
summary(tweets$attention)
sd(tweets$attention)
dataset$popularity <- normalize(dataset$replies_count)+
normalize(dataset$retweets_count)+normalize(dataset$likes_count)
correlation <- select(dataset, likes_count, replies_count, retweets_count, popularity)
correlation$username <- NULL
jpeg('~/Documents/GitHub/OT_analysis/results/correlation.jpg', width = 800, height = 800, res=200)
chart.Correlation(correlation, histogram=TRUE, pch=19)
dev.off()
778*0.7
View(locations)
View(country)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(readr)
library(tidytext)
library(stringr)
library(scales)
library(readxl)
#install.packages(c("quanteda", "xtable", "htmlwidgets", "webshot"))
library(quanteda)
library(xtable)
library(htmlwidgets)
library(webshot)
rm(list=ls())
laod(file = "~/Documents/GitHub/OT_analysis/data/dataset_final.RData")
load(file = "~/Documents/GitHub/OT_analysis/data/dataset_final.RData")
ID_list <- dataset %>%
distinct(username, .keep_all = TRUE) #34435
unique_ID <- ID_list[1:2]
ID_list <- select(ID_list, year, date, user_id, username, name, mentions, reply_to)
write.csv(unique_ID, file="~/Documents/GitHub/OT_analysis/data/unique_ID_final.csv")
myvars <- c("username", "year")
all_users <- dataset[myvars]
length(unique(all_users$username)) #34370 unique users
#tweeting pattern of users
tab_form <- all_users %>%
group_by(year) %>%
count(username) #users with how frequently they posted all years
summary(tab_form$Freq) #average number of post = 3 / median = 1 / 75% = 2
range(tab_form$Freq) #number of posts ranges from 1 to 11372
options(scipen=999)
totals <- all_users %>%
group_by(year) %>%
summarize(total = length(unique(username))) %>%
mutate(Value="Account")
top_n(tab_form, 10, Freq) #only four users posted more than 100 times over the decade.
View(tab_form)
top <- tab_form %>%
group_by(year) %>%
top_n(10, n) %>%
ungroup()
View(top)
View(tab_form)
View(totals)
View(top)
top <- tab_form %>%
group_by(year) %>%
top_n(5, n) %>%
ungroup()
plot(top)
ggplot(top, aes(username, n, group=username)) +
geom_bar(stat = "identity") +
facet_wrap(~ year, scales = "free", ncol=4) +
theme_classic()
ggplot(top, aes(username, n, group=username)) +
geom_bar(stat = "identity") +
facet_wrap(~ year, scales = "free", ncol=3) +
theme_classic()
ggplot(top, aes(username, n, group=username)) +
geom_bar(stat = "identity") +
facet_wrap(~ year, scales = "free", ncol=3) +
theme_classic() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(top, aes(username, n, group=username)) +
geom_bar(stat = "identity") +
facet_wrap(~ year, scales = "free", ncol=3) +
theme_classic() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
jpeg('~/Documents/GitHub/OT_analysis/results/top_posters.jpg', width = 1500, height = 1500, res=200)
ggplot(top, aes(username, n, group=username)) +
geom_bar(stat = "identity") +
facet_wrap(~ year, scales = "free", ncol=3) +
theme_classic() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
dev.off()
jpeg('~/Documents/GitHub/OT_analysis/results/top_posters.jpg', width = 1500, height = 1500, res=300)
ggplot(top, aes(username, n, group=username)) +
geom_bar(stat = "identity") +
facet_wrap(~ year, scales = "free", ncol=3) +
xlab("Usernmae") + ylab("Count") +
theme_classic() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
dev.off()
jpeg('~/Documents/GitHub/OT_analysis/results/top_posters.jpg', width = 1500, height = 1500, res=200)
ggplot(top, aes(username, n, group=username)) +
geom_bar(stat = "identity") +
facet_wrap(~ year, scales = "free", ncol=3) +
xlab("Usernmae") + ylab("Count") +
theme_classic() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
dev.off()
graph2013_0 <- read.csv(file="~/Documents/GitHub/OT_analysis/results/sentiment/graph2013_0.csv")
graph2016_4 <- read.csv(file="~/Documents/GitHub/OT_analysis/results/sentiment/graph2016_4.csv")
graph2019_7 <- read.csv(file="~/Documents/GitHub/OT_analysis/results/sentiment/graph2019_7.csv")
graph <- rbind(graph2013_0, graph2016_4, graph2019_7)
table(graph)
graph <- graph %>%
count(year, predicted) %>%
group_by(year) %>%
mutate(ratio = n/sum(n))
graph_n <- graph[graph$predicted=="n",]
graph$year <- as.factor(graph$year)
p1 <- ggplot(graph, aes(year, y=n, fill=predicted)) +
geom_bar(stat="identity", position=position_dodge()) +
geom_text(aes(label=n), vjust=-0.5,
position = stacked, size=3) +
scale_fill_discrete(name="Predicted Value",
breaks=c("p", "n"),
labels=c("Positive", "Negative")) +
xlab("Year") + ylab("Number of Tweets") + theme_classic() +
theme(legend.position = "bottom")
p1 <- ggplot(graph, aes(year, y=n, fill=predicted)) +
geom_bar(stat="identity", position=position_dodge()) +
geom_text(aes(label=n), vjust=-0.5,
position = "stacked", size=3) +
scale_fill_discrete(name="Predicted Value",
breaks=c("p", "n"),
labels=c("Positive", "Negative")) +
xlab("Year") + ylab("Number of Tweets") + theme_classic() +
theme(legend.position = "bottom")
p1 <- ggplot(graph, aes(year, y=n, fill=predicted)) +
geom_bar(stat="identity", position=position_dodge()) +
geom_text(aes(label=n), vjust=-0.5,
position = "stack", size=3) +
scale_fill_discrete(name="Predicted Value",
breaks=c("p", "n"),
labels=c("Positive", "Negative")) +
xlab("Year") + ylab("Number of Tweets") + theme_classic() +
theme(legend.position = "bottom")
p1
p1 <- ggplot(graph, aes(year, y=n, fill=predicted)) +
geom_bar(stat="identity", position="stack") +
geom_text(aes(label=n), vjust=-0.5,
position = position_dodge(0.9), size=3) +
scale_fill_discrete(name="Predicted Value",
breaks=c("p", "n"),
labels=c("Positive", "Negative")) +
xlab("Year") + ylab("Number of Tweets") + theme_classic() +
theme(legend.position = "bottom")
p1
ggplot(graph, aes(year, y=n, fill=predicted)) +
geom_bar(stat="identity", position="stack") +
geom_text(aes(label=n), vjust=-1,
position = position_dodge(0.9), size=3) +
scale_fill_discrete(name="Predicted Value",
breaks=c("p", "n"),
labels=c("Positive", "Negative")) +
xlab("Year") + ylab("Number of Tweets") + theme_classic() +
theme(legend.position = "bottom")
ggplot(graph, aes(year, y=n, fill=predicted)) +
geom_bar(stat="identity", position="stack") +
geom_text(aes(label=n), vjust=-2,
position = position_dodge(0.9), size=3) +
scale_fill_discrete(name="Predicted Value",
breaks=c("p", "n"),
labels=c("Positive", "Negative")) +
xlab("Year") + ylab("Number of Tweets") + theme_classic() +
theme(legend.position = "bottom")
ggplot(graph, aes(year, y=n, fill=predicted)) +
geom_bar(stat="identity", position="stack") +
geom_text(aes(label=n), vjust=0.5,
position = position_dodge(0.9), size=3) +
scale_fill_discrete(name="Predicted Value",
breaks=c("p", "n"),
labels=c("Positive", "Negative")) +
xlab("Year") + ylab("Number of Tweets") + theme_classic() +
theme(legend.position = "bottom")
ggplot(graph, aes(year, y=n, fill=predicted)) +
geom_bar(stat="identity", position="stack") +
geom_text(aes(label=n), position = position_stack(vjust = 0.5), size=3) +
scale_fill_discrete(name="Predicted Value",
breaks=c("p", "n"),
labels=c("Positive", "Negative")) +
xlab("Year") + ylab("Number of Tweets") + theme_classic() +
theme(legend.position = "bottom")
ggplot(graph_n, aes(year, y=ratio*100, group=1)) +
geom_line(size=1, color="black") +
geom_label(aes(label=paste0(round(ratio*100,2), "%"))) +
xlab("Year") + ylab("Percentage of negative tweets (%)") + theme_classic() +
theme(legend.position = "bottom")
View(graph)
View(graph2013_0)
graph <- rbind(graph2013_0, graph2016_4, graph2019_7)
graph <- graph %>%
count(predicted) %>%
group_by(year) %>%
mutate(ratio = n/sum(n))
graph <- graph %>%
group_by(year) %>%
count(predicted) %>%
mutate(ratio = n/sum(n))
View(graph)
dataset_ot <- filter(dataset, grepl("orphanage tourism", tweet))
uniqueid <- unique(dataset_ot$username)
length(uniqueid)/length(unique(dataset$username))
table(dataset_ot$year)
graph <- dataset_ot %>%
select(year, username) %>%
distinct()
graph <- graph[order(graph$username, graph$year),]
graph <- graph %>%
group_by(username) %>%
arrange(order(year)) %>%
slice(1) %>%
ungroup()
graph <- graph %>%
group_by(year) %>%
count()
graph2013_0 <- read.csv(file="~/Documents/GitHub/OT_analysis/results/sentiment/graph2013_0.csv")
graph2016_4 <- read.csv(file="~/Documents/GitHub/OT_analysis/results/sentiment/graph2016_4.csv")
graph2019_7 <- read.csv(file="~/Documents/GitHub/OT_analysis/results/sentiment/graph2019_7.csv")
#dataset_ot <- filter(dataset, grepl("orphanage tourism", tweet))
#dataset_ot <- rbind(dataset_ot, filter(dataset, grepl("voluntourism", tweet)))
#dataset_ot <- rbind(dataset_ot, filter(dataset, grepl("volunteer tourism", tweet)))
dataset_n <- rbind(graph2019_7, graph2016_4, graph2013_0)
dataset$sentiment <- dataset_n$predicted
dataset_n <- dataset[dataset$sentiment=="n",]
graph_n <- dataset_n %>%
select(year, username) %>%
distinct()
graph <- dataset %>%
select(year, username) %>%
distinct()
graph_n <- graph_n %>%
group_by(year) %>%
count()
graph <- graph %>%
group_by(year) %>%
count()
colnames(graph)[2] <- "total"
graph_n <- inner_join(graph_n, graph)
graph_n$Total <- 34370
graph_n$p <- round(graph_n$n/graph_n$total*100,2)
graph_n$cum <- round(cumsum(graph_n$n)/34370*100,2)
graph_n$cumsum <- cumsum(graph_n$n)
ggplot(graph_n, aes(as.factor(year), y=p)) +
geom_bar(stat="identity",
position=position_dodge()) +
geom_text(aes(label=p), vjust=-0.5,
position = position_dodge(0.9), size=4) +
xlab("Year") + ylab("Percentage of Users") +
theme_classic() +
theme(legend.position = "bottom") +
theme(legend.title = element_blank()) +
theme(text = element_text(size=15))
ggplot(graph, aes(year, y=n, fill=predicted)) +
geom_bar(stat="identity", position="stack") +
geom_text(aes(label=n), position = position_stack(vjust = 0.5), size=3) +
scale_fill_discrete(name="Predicted Value",
breaks=c("p", "n"),
labels=c("Positive", "Negative")) +
xlab("Year") + ylab("Number of Tweets") + theme_classic() +
theme(legend.position = "bottom")
View(graph)
View(dataset_n)
id <- select(datset, username, year, sentiment)
id <- select(dataset, username, year, sentiment)
View(id)
dataset$sentiment1 <- ifelse(dataset[grepl("orphanage tourism", tweet),], "n", dataset$sentiment)
dataset$sentiment1 <- ifelse(dataset[grepl("orphanage tourism", dataset$tweet),], "n", dataset$sentiment)
dataset$sentiment1 <- ifelse(grepl(dataset$tweet, "orphanage tourism")==TRUE,], "n", dataset$sentiment)
dataset$sentiment1 <- ifelse(grepl(dataset$tweet, "orphanage tourism")==TRUE), "n", dataset$sentiment)
dataset$sentiment1 <- ifelse(grepl(dataset$tweet, "orphanage tourism")==TRUE, "n", dataset$sentiment)
dataset$sentiment1 <- dataset$sentiment
dataset[grep("orphanage tourism", dataset$tweet),]$sentiment1 <- "n"
dataset_n1 <- dataset[dataset$sentiment1=="n",]
graph_n1 <- dataset_n1 %>%
select(year, username) %>%
distinct()
graph_n1 <- graph_n1 %>%
group_by(year) %>%
count()
View(graph_n1)
View(graph_n)
View(graph_n1)
View(id)
View(id)
id <- select(dataset, username, year, sentiment) %>%
distinct()
View(id)
View(id)
id <- id[id$sentiment=="n",]
write.csv(id, file="~Downloads/id.csv")
write.csv(id, file="~/Downloads/id.csv")
sum(table(id$username)-1)
sum(table(id$username))
table(id$username)
sum(table(id$username)-1)
unique <- unique(id$username)
sum(unique(id$username))
summary(unique(id$username))
View(id)
id <- select(dataset, username, year, sentiment) %>%
distinct()
View(id)
id <- id[id$sentiment=="n",]
sum(table(id$username)-1)
summary(unique(id$username))
719/10266
id <- select(dataset, username, year, sentiment) %>%
distinct()
id <- id[id$sentiment=="p",]
sum(table(id$username)-1)
summary(unique(id$username))
2673/26968
ggplot(graph_n, aes(as.factor(year), y=cumsum)) +
geom_bar(stat="identity",
position=position_dodge()) +
geom_text(aes(label=p), vjust=-0.5,
position = position_dodge(0.9), size=4) +
xlab("Year") + ylab("Percentage of Users") +
theme_classic() +
theme(legend.position = "bottom") +
theme(legend.title = element_blank()) +
theme(text = element_text(size=15))
ggplot(graph_n, aes(as.factor(year), y=cum)) +
geom_bar(stat="identity",
position=position_dodge()) +
geom_text(aes(label=p), vjust=-0.5,
position = position_dodge(0.9), size=4) +
xlab("Year") + ylab("Percentage of Users") +
theme_classic() +
theme(legend.position = "bottom") +
theme(legend.title = element_blank()) +
theme(text = element_text(size=15))
#set working directory
setwd("~/Documents/GitHub/RIDB-Watchman")
library(readr)
library(data.table)
require(psych)
require(dplyr)
require(tidyr)
require(reshape2)
require(lubridate)
rm(list=ls())
#load data
facilities <- fread("~/Downloads/reservations2019.csv") #campsite characteristics
head(facilities)
glimpse(facilities)
Watchman <- facilities[facilities$facilityid==232445,] #watchman campground info
View(Watchman)
Watchman <- facilities[facilities$park=="WATCHMAN CAMPGROUND",] #watchman campground info
glimpse(facilities)
fwrite(reservation, file = "~/Documents/GitHub/RIDB-Watchman/Watchman2019.csv")
fwrite(Watchman, file = "~/Documents/GitHub/RIDB-Watchman/Watchman2019.csv")
#load data
#facilities <- fread("~/Documents/GitHub/RIDB-Watchman/RIDBFullExport_V1_CSV/Facilities_API_v1.csv") #campsite characteristics
#glimpse(facilities)
#Watchman <- facilities[facilities$FacilityName=="WATCHMAN CAMPGROUND",] #watchman campground info
rm(facilities)
rm(facilities, Watchman
)
watchman <- fread("~/Downloads/reservations2019.csv")
watchman <- fread("~/Documents/GitHub/RIDB-Watchman/Watchman2019.csv")
reservation <- watchman
unique(reservation$regiondescription) # Zion National Park
unique(reservation$parentlocation) # Zion National Park
unique(reservation$park) # Watchman
count(reservation, 'hisoricalreservationid') # 28522 obersvations
count(distinct(reservation)) # 28522 obersvations
camp <- reservation[grepl("Overnight", reservation[["UseType"]]), ] # all are campsites
camp <- reservation[grepl("Overnight", reservation[["usetype"]]), ] # all are campsites
unique(camp$productid) #189
count(unique(camp$productid)) #189
count(distinct(camp$productid)) #189
summary(unique(camp$productid)) #189
desc(unique(camp$productid)) #189
length(unique(camp$productid)) #189
unique(camp$sitetype)
unique(camp$entityid) #189 <- this is the CampsiteID
unique(camp$facilityid) #189 <- this is the CampsiteID
unique(camp$legacyfacilityid) #189 <- this is the CampsiteID
unique(camp$usetype) #189 <- this is the CampsiteID
unique(camp$inventorytype) #189 <- this is the CampsiteID
unique(camp$equipmentdescription) #189 <- this is the CampsiteID
head(camp)
View(watchman)
#calculate difference between the reservation date and the start date
camp$bookingWindow <- as.Date(as.character(camp$startdate), format="%Y-%m-%d") - as.Date(as.character(camp$orderdate), format="%Y-%m-%d")
camp$bookingWindow <- as.numeric(camp$bookingWindow)
summary(camp$bookingWindow) #there are negative booking windows
camp[camp$bookingWindow<0 ,] #there are 9 negative date differences between the reservation and the start date. This could be system error.
View(camp)
View(camp)
camp <- camp[camp$bookingWindow>-1,] #remove 737 negative booking window (data reduced from 28522 to 28513)
summary(camp$bookingWindow)
#calculate difference between the end date and the start date
camp$lengthStay <- as.Date(as.character(camp$enddate), format="%Y-%m-%d") - as.Date(as.character(camp$startdate), format="%Y-%m-%d")
camp$lengthStay <- as.numeric(camp$lengthStay) #number of nights stayed
summary(camp$lengthStay) # no negative length of stay
View(camp)
#calculate difference between the end date and the start date
camp$lengthStay <- as.Date(as.character(camp$enddate), format="%Y-%m-%d") - as.Date(as.character(camp$startdate), format="%Y-%m-%d")
camp$lengthStay <- as.numeric(camp$lengthStay) #number of nights stayed
summary(camp$lengthStay) # no negative length of stay
camp[camp$lengthStay<0 ,]
#mean 2 days, max 16 days
glimpse(camp)
camp <- camp[camp$lengthStay>-1,] #remove 737 negative booking window (data reduced from 24676 to 23939)
#mean 2 days, max 16 days
glimpse(camp)
summary(camp$lengthStay)
View(camp)
campsites <- fread("~/Documents/GitHub/RIDB-Watchman/RIDBFullExport_V1_CSV/Campsites_API_v1.csv") #campsite characteristics
campsites <- fread("~/Documents/GitHub/RIDB-Watchman/data/Campsites_API_v1.csv") #campsite characteristics
campsites <- campsites[campsites$FacilityID==232445,]
glimpse(campsites)
unique(campsites$CampsiteType)
View(campsites)
